{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8It-pQU5FDJ"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from itertools import combinations\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def n_grams_word(text, k):\n",
        "  vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b', ngram_range=(k,k))\n",
        "  X = vectorizer.fit_transform(text)\n",
        "  return vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "VJjl9hPGHQdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def n_grams_char(text, k):\n",
        "  vectorizer = CountVectorizer(analyzer=\"char\", ngram_range=(k,k))\n",
        "  X = vectorizer.fit_transform(text)\n",
        "  return vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "9xweIanesMKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(text, comb):\n",
        "\n",
        "  for c in comb:\n",
        "    d_a = c[0]\n",
        "    d_b = c[1]\n",
        "\n",
        "    k_grams_char_2_a = set(n_grams_char([text[d_a]], 2))\n",
        "    k_grams_char_2_b = set(n_grams_char([text[d_b]], 2))\n",
        "\n",
        "    k_grams_char_3_a = set(n_grams_char([text[d_a]], 3))\n",
        "    k_grams_char_3_b = set(n_grams_char([text[d_b]], 3))\n",
        "\n",
        "    n_grams_word_a = set(n_grams_word([text[d_a]], 2))\n",
        "    n_grams_word_b = set(n_grams_word([text[d_b]], 2))\n",
        "\n",
        "    intersection_2_char = len(k_grams_char_2_a.intersection(k_grams_char_2_b))\n",
        "    intersection_3_char = len(k_grams_char_3_a.intersection(k_grams_char_3_b))\n",
        "    intersection_word = len(n_grams_word_a.intersection(n_grams_word_b))\n",
        "\n",
        "    union_2_char = len(k_grams_char_2_a.union(k_grams_char_2_b))\n",
        "    union_3_char = len(k_grams_char_3_a.union(k_grams_char_3_b))\n",
        "    union_word = len(n_grams_word_a.union(n_grams_word_b))\n",
        "    \n",
        "    print(f\"Jaccard Similarity {c} for k-gram for 2 characters: {intersection_2_char/union_2_char}\")\n",
        "    print(f\"Jaccard Similarity {c} for k-gram for 3 characters: {intersection_3_char/union_3_char}\")\n",
        "    print(f\"Jaccard Similarity {c} for k-gram for 2 word: {intersection_word/union_word}\")"
      ],
      "metadata": {
        "id": "bf3zu9XIPhFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mult_hashing(x, a, i, m = 10000):\n",
        "  return (x*(a+i)/2**(x % 1)) % m"
      ],
      "metadata": {
        "id": "neeIR0lDg1Tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def min_hashing(k_gram, k):\n",
        "  v = np.full((1, k), np.inf)\n",
        "  for g in k_gram:\n",
        "    for j in range(k):\n",
        "      s = int(g.encode('utf-8').hex(),16)\n",
        "      # a_lst = [10, 42, 313, 739, 852]\n",
        "      # a = 0.7867\n",
        "      # a = 57683\n",
        "      # a = 97683\n",
        "      a = 852\n",
        "      # s = sha1_hashing(g,j)\n",
        "      h = mult_hashing(s,a,j)\n",
        "      if (h < v[0][j]):\n",
        "        v[0][j] = h\n",
        "  return v"
      ],
      "metadata": {
        "id": "lOw9vEwkdmVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_hashing(m_a, m_b, k):\n",
        "  c = []\n",
        "  for i, x in enumerate(m_a):\n",
        "    if x == m_b[i]:\n",
        "      c.append(1)\n",
        "  return sum(c)/k"
      ],
      "metadata": {
        "id": "VoEkgOwcpCUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main\n",
        "url = \"https://raw.githubusercontent.com/koaning/icepickle/main/datasets/imdb_subset.csv\"\n",
        "df = pd.read_csv(url) # This is how you read a csv file to a pandas frame \n",
        "corpus = list(df['text'])\n",
        "corpus_small = corpus[:4] # This is a list of 4 movie reviews\n",
        "\n",
        "k_grams_word = []\n",
        "k_grams_char_2 = []\n",
        "k_grams_char_3 = []\n",
        "\n",
        "for c in corpus_small:\n",
        "  c_lst = [c]\n",
        "  k_grams_char_2.append(n_grams_char(c_lst, 2))\n",
        "  k_grams_char_3.append(n_grams_char(c_lst, 3))\n",
        "  k_grams_word.append(n_grams_word(c_lst, 2))\n",
        "\n",
        "for i, k in enumerate(k_grams_char_2):\n",
        "  print(f\"length 2-gram char D{i}: {len(k)}\\n{k[0:10]}\")\n",
        "print('\\n')\n",
        "for i, k in enumerate(k_grams_char_3):\n",
        "  print(f\"length 3-gram char D{i}: {len(k)}\\n{k[0:10]}\")\n",
        "print('\\n')\n",
        "for i, k in enumerate(k_grams_word):\n",
        "  print(f\"length 2-gram word D{i}: {len(k)}\\n{k[0:10]}\")\n",
        "\n",
        "r = np.arange(0,len(corpus_small))\n",
        "comb = list(combinations(r, 2))\n",
        "jaccard_similarity(corpus_small, comb)\n",
        "\n",
        "d1 = open('/content/drive/MyDrive/Spring2023/CS4140/D1.txt', 'r')\n",
        "d2 = open('/content/drive/MyDrive/Spring2023/CS4140/D2.txt', 'r')\n",
        "\n",
        "corpus_docs = [d1.read(), d2.read()]\n",
        "kgrams_hash = []\n",
        "\n",
        "for c in corpus_docs:\n",
        "  c_lst = [c]\n",
        "  kgrams_hash.append(n_grams_char(c_lst, 3))\n",
        "\n",
        "k_lst = [20, 60, 150, 300, 450, 600, 750, 800, 1000]\n",
        "for k in k_lst:\n",
        "  start = time.time()\n",
        "  fast_mh_a = min_hashing(kgrams_hash[0], k) \n",
        "  fast_mh_b = min_hashing(kgrams_hash[1], k) \n",
        "  jh = jaccard_hashing(fast_mh_a[0], fast_mh_b[0], k)\n",
        "  end = time.time()\n",
        "  print(f\"jaccard hashing for k = {k} : {jh}\")\n",
        "  print(\"duration = \", end-start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7rixDalqZlL",
        "outputId": "2fd4cda1-e882-4cc3-ed92-ca17c2d0e87b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length 2-gram char D0: 333\n",
            "[' \"' ' (' ' /' ' 1' ' 3' ' 4' ' a' ' b' ' c' ' d']\n",
            "length 2-gram char D1: 461\n",
            "[' \"' ' (' ' -' ' /' ' 1' ' 2' ' a' ' b' ' c' ' d']\n",
            "length 2-gram char D2: 401\n",
            "[' \"' ' (' ' /' ' 1' ' 2' ' a' ' b' ' c' ' d' ' e']\n",
            "length 2-gram char D3: 154\n",
            "[' 1' ' 4' ' a' ' b' ' c' ' d' ' e' ' f' ' g' ' h']\n",
            "\n",
            "\n",
            "length 3-gram char D0: 933\n",
            "[' \"w' ' (a' ' (g' ' />' ' 10' ' 30' ' 4/' ' a ' ' ab' ' ac']\n",
            "length 3-gram char D1: 1714\n",
            "[' \"a' ' \"b' ' \"d' ' \"e' ' \"g' ' \"h' ' \"m' ' \"s' ' (\"' ' (a']\n",
            "length 3-gram char D2: 1428\n",
            "[' \"c' ' \"l' ' \"o' ' \"p' ' \"r' ' (\"' ' (i' ' (s' ' (t' ' />']\n",
            "length 3-gram char D3: 256\n",
            "[' 1 ' ' 40' ' a ' ' af' ' al' ' an' ' at' ' av' ' ba' ' be']\n",
            "\n",
            "\n",
            "length 2-gram word D0: 349\n",
            "['106 minutes' '30 minutes' '4 10' 'a beautiful' 'a complete' 'a girl'\n",
            " 'a lot' 'a nice' 'a pretty' 'a promising']\n",
            "length 2-gram word D1: 908\n",
            "['1930s among' '1937 and' '1937 but' '20th century' 'a bad' 'a bit'\n",
            " 'a brawl' 'a break' 'a conclusion' 'a contest']\n",
            "length 2-gram word D2: 596\n",
            "['1960 s' '2005 qualified' 'a blonde' 'a burning' 'a cause' 'a cry'\n",
            " 'a few' 'a half' 'a heavy' 'a magnificent']\n",
            "length 2-gram word D3: 63\n",
            "['1 only' '40 minutes' 'a 1' 'a single' 'after 40' 'all costs' 'and after'\n",
            " 'and there' 'at all' 'avoid this']\n",
            "Jaccard Similarity (0, 1) for k-gram for 2 characters: 0.591182364729459\n",
            "Jaccard Similarity (0, 1) for k-gram for 3 characters: 0.3268170426065163\n",
            "Jaccard Similarity (0, 1) for k-gram for 2 word: 0.018638573743922204\n",
            "Jaccard Similarity (0, 2) for k-gram for 2 characters: 0.6203090507726269\n",
            "Jaccard Similarity (0, 2) for k-gram for 3 characters: 0.3102108768035516\n",
            "Jaccard Similarity (0, 2) for k-gram for 2 word: 0.020518358531317494\n",
            "Jaccard Similarity (0, 3) for k-gram for 2 characters: 0.407514450867052\n",
            "Jaccard Similarity (0, 3) for k-gram for 3 characters: 0.17839444995044598\n",
            "Jaccard Similarity (0, 3) for k-gram for 2 word: 0.007334963325183374\n",
            "Jaccard Similarity (1, 2) for k-gram for 2 characters: 0.6640926640926641\n",
            "Jaccard Similarity (1, 2) for k-gram for 3 characters: 0.40080249665626394\n",
            "Jaccard Similarity (1, 2) for k-gram for 2 word: 0.0273224043715847\n",
            "Jaccard Similarity (1, 3) for k-gram for 2 characters: 0.30851063829787234\n",
            "Jaccard Similarity (1, 3) for k-gram for 3 characters: 0.11931818181818182\n",
            "Jaccard Similarity (1, 3) for k-gram for 2 word: 0.004136504653567736\n",
            "Jaccard Similarity (2, 3) for k-gram for 2 characters: 0.3470873786407767\n",
            "Jaccard Similarity (2, 3) for k-gram for 3 characters: 0.12566844919786097\n",
            "Jaccard Similarity (2, 3) for k-gram for 2 word: 0.001519756838905775\n",
            "jaccard hashing for k = 20 : 0.95\n",
            "duration =  0.038639068603515625\n",
            "jaccard hashing for k = 60 : 0.9333333333333333\n",
            "duration =  0.12038326263427734\n",
            "jaccard hashing for k = 150 : 0.9666666666666667\n",
            "duration =  0.3153953552246094\n",
            "jaccard hashing for k = 300 : 0.9533333333333334\n",
            "duration =  0.6293189525604248\n",
            "jaccard hashing for k = 450 : 0.9488888888888889\n",
            "duration =  1.2392771244049072\n",
            "jaccard hashing for k = 600 : 0.9483333333333334\n",
            "duration =  1.1984784603118896\n",
            "jaccard hashing for k = 750 : 0.944\n",
            "duration =  1.5068597793579102\n",
            "jaccard hashing for k = 800 : 0.945\n",
            "duration =  1.6111719608306885\n",
            "jaccard hashing for k = 1000 : 0.946\n",
            "duration =  1.9983856678009033\n"
          ]
        }
      ]
    }
  ]
}